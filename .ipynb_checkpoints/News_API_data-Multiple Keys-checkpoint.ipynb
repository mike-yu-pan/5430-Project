{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f88f868",
   "metadata": {},
   "source": [
    "# Retrieving and Writing New York Times article into a JSON file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a9e85",
   "metadata": {},
   "source": [
    "### NYT API: Article search (the only section we need to extract all titles)\n",
    "* **RESTRICTION-** the maximum number of articles that can be returned at once: 10\n",
    "* Use the Article Search API to look up articles by keyword. You can refine your search using filters and facets.\n",
    "* reference: https://ashar180.medium.com/crawling-ny-times-api-for-relevant-articles-b6134b651054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e1448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ec511fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time #for delaying retrieval\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cbeb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to get your own in New York Times API\n",
    "api_key1 = 'your_own_api_key1'\n",
    "api_key2 = 'your_friend_api_key2'\n",
    "# api_key3 = 'own_key'\n",
    "# api_key4 = 'own_key'\n",
    "# api_key5 = 'own_key'\n",
    "# api_key6 = 'own_key'\n",
    "# api_key7 = 'own_key'\n",
    "# api_key8 = 'own_key'\n",
    "# api_key9 = 'own_key'\n",
    "# api_key10 = 'own_key'\n",
    "# api_key11 = 'own_key'\n",
    "# api_key12 = 'own_key'\n",
    "# api_key13 = 'own_key'\n",
    "# api_key14 = 'own_key'\n",
    "# api_key15 = 'own_key'\n",
    "# api_key16 = 'own_key'\n",
    "# api_key17 = 'own_key'\n",
    "# api_key18 = 'own_key'\n",
    "# api_key19 = 'own_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a5a604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_keys = [api_key1, api_key2] #, api_key3, api_key4, api_key5, api_key6, api_key7, api_key8, api_key9, api_key10, api_key11, api_key12, api_key13, api_key14, api_key15, api_key16, api_key17, api_key18, api_key19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5c4b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dfbab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import titles from imdb\n",
    "import pandas as pd\n",
    "query_list = pd.read_csv('unique_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78966bf2",
   "metadata": {},
   "source": [
    "Querying only for movie titles with start year >2020 or null because we only want recent information since audience preferences may change over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8daa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query only movies start year> 2000 or is null\n",
    "default_year = 2000  # Replace '\\\\N' with this default value\n",
    "query_list['startYear'] = query_list['startYear'].replace('\\\\N', 0)\n",
    "query_list['startYear'] = query_list['startYear'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84a6fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = query_list.loc[query_list['startYear'] > 2020, 'primaryTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daebf08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.16675"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_list)/4000*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "177aa0d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: Mq4LOxs0B3o0oHjxNH4WVXupXaHqCswB\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: Oe5z2TqFkBykOO9AKUmN7eIpfULuHTtl\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: 0HEa6jjsrRLPa6yYsQo1XdsYlHfhBwqg\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: dktNmBFJQdto0OA06CPQUdxWgwHrMsE9\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: btEcbjWBtm0lxibRaoQBJb0e4lT113iN\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: UwbYWW5yDf0r4o0xmK3qTwHUTlN4MdYg\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: ePx5Dc90Wz6cj8Lk3AqAskbCVz0d0nNu\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: ycFL8N0HJNIZslsdmknU5slzgnPmy0sJ\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: xt3Ecb1KhqWBCf1SNSfEP8Eaa00IXLSu\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: mwJjmYyLTSs0CqrbK8XZkpB7s1do4Eqs\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: 2sXNeLQ9IeKKXSv4RvvWS76mNCmD2ohT\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: p3QnItGOEa5nkvpnYuWhubB6wuzG1IY3\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: g5lUb3VrL7JyNrq3WSgx8OObodvptM4q\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: LoTCr10Yztt6wXXeBPiTyYi06uSOg0js\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: fJnyVxipe97NM6fsnzSgCWQRzsRwqIr3\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: lwzS0tvSAUe4DH5tPHxRv5Q0OLuCLVIc\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: 55yuXb0YZPzb0OgxQyDOlbE2ymDAs6JB\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "Using API key: KOlU5S0qDwCSFAq1ZRBs20RraITmsrJy\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n",
      "Rate limit exceeded for current API key. Switching to the next one.\n",
      "All API keys have been used. Exiting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_list = query_list\n",
    "\n",
    "all_articles = []\n",
    "\n",
    "def fetch_articles_with_api_key(api_key, movie_title):\n",
    "    page_number = 0 #resets page number for each movie_title (define page by each movie instead of the whole list of movie titles)\n",
    "\n",
    "    while True:\n",
    "        encoded_title = quote(movie_title) \n",
    "      \n",
    "        query_params = {\n",
    "            \"api-key\": api_key,\n",
    "            \"q\": encoded_title,\n",
    "            \"fq\": \"news_desk:Movies\",\n",
    "            \"begin_date\": 18510101, #start date of articles set to 1851 because articles before 1851 are arhchived, however, since movie titles are focused on >2020, the returned dates shouldn't be too long before 2020 (since there probably wouldn't be articles for the movie until planned production)\n",
    "            \"sort\": \"newest\",\n",
    "            \"page\": page_number  # Pagination, page 0 will return the first page of results\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=query_params)\n",
    "\n",
    "        # Process the data as per your requirements\n",
    "        if response.status_code == 200: #request code 200 means the call was successful\n",
    "            data = response.json()\n",
    "            total_hits = data['response']['meta']['hits']\n",
    "            print(f\"Total results found for '{movie_title}':\", total_hits)\n",
    "\n",
    "            articles = data['response']['docs']\n",
    "\n",
    "            #check if there's any articles left to loop through\n",
    "            if not articles: #if there's no article returned aka no more articles for the movie, = true\n",
    "                break #stop the loop \n",
    "\n",
    "            #loop to load article in json \n",
    "            for article in articles:\n",
    "                # Initialize author to an empty string\n",
    "                author = \"\"\n",
    "                \n",
    "                # Extract relevant fields from the article\n",
    "                headline = article.get('headline', {}).get('main', '')\n",
    "                abstract = article.get('abstract', '')\n",
    "                lead_paragraph = article.get('lead_paragraph', '')\n",
    "                snippet = article.get('snippet', '')\n",
    "                pub_date = article.get('pub_date', '')\n",
    "                news_desk = article.get('news_desk', '')\n",
    "                web_url = article.get('web_url', '')\n",
    "                source = article.get('source', '')\n",
    "                \n",
    "                persons = article.get('byline', {}).get('person', [])\n",
    "                for person in persons:\n",
    "                    first_name = person.get('firstname', '')\n",
    "                    last_name = person.get('lastname', '')\n",
    "                    if first_name and last_name:\n",
    "                        author = f\"{first_name} {last_name}\"\n",
    "                        break\n",
    "                    elif first_name:\n",
    "                        author = first_name\n",
    "                        break\n",
    "                    elif last_name:\n",
    "                        author = last_name\n",
    "                        break\n",
    "\n",
    "                if not author:\n",
    "                    author = \"N/A\"\n",
    "\n",
    "                article_info = {\n",
    "                    \"Headline\": headline,\n",
    "                    \"Abstract\": abstract,\n",
    "                    \"Lead_Paragraph\": lead_paragraph,\n",
    "                    \"Snippet\": snippet,\n",
    "                    \"Published_date\": pub_date,\n",
    "                    \"Author\": author,\n",
    "                    \"News_desk\": news_desk,\n",
    "                    \"URL\": web_url,\n",
    "                    \"Source\": source\n",
    "                }\n",
    "\n",
    "                all_articles.append(article_info)\n",
    "           \n",
    "            page_number += 1\n",
    "\n",
    "            #delay in abstracting bc there's a limit on how many articles you can retrieve based on time\n",
    "            time.sleep(1)  \n",
    "\n",
    "        elif response.status_code == 429:\n",
    "            # Rate limit exceeded, switch to the next API key\n",
    "            print(\"Rate limit exceeded for current API key. Switching to the next one.\")\n",
    "            if api_keys:\n",
    "                next_api_key = api_keys.pop(0)\n",
    "                print(\"Using API key:\", next_api_key)\n",
    "                fetch_articles_with_api_key(next_api_key, movie_title)\n",
    "            else:\n",
    "                print(\"All API keys have been used. Exiting.\")\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            print(\"Error:\", response.status_code)\n",
    "            break\n",
    "\n",
    "for movie_title in query_list:\n",
    "    for api_key in api_keys:\n",
    "        fetch_articles_with_api_key(api_key, movie_title)\n",
    "\n",
    "\n",
    "# Save the final version of all_articles to a JSON file after all movie titles are processed\n",
    "with open(\"nyt_articles_all.json\", \"w\") as json_file:\n",
    "    json.dump(all_articles, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
