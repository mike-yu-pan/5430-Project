{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f88f868",
   "metadata": {},
   "source": [
    "# Retrieving and Writing New York Times article into a JSON file \n",
    "* Reference: https://medium.com/@danalindquist/using-new-york-times-api-and-jq-to-collect-news-data-a5f386c7237b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73e1448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "880bc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18acf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to get your own in New York Times API\n",
    "api_key = your_own_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a9e85",
   "metadata": {},
   "source": [
    "### NYT API: Article search (the only section we need to extract all titles)\n",
    "* **RESTRICTION-** the maximum number of articles that can be returned at once: 10\n",
    "* Use the Article Search API to look up articles by keyword. You can refine your search using filters and facets.\n",
    "* reference: https://ashar180.medium.com/crawling-ny-times-api-for-relevant-articles-b6134b651054\n",
    "* did not use movie review search bc it doesn't include context or URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ec511fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time #for delaying retrieval\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51934e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?q=' + query + '&api-key=' + api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cbeb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to get your own in New York Times API\n",
    "api_key = 'your_own_api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5c4b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7dfbab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import titles from imdb\n",
    "import pandas as pd\n",
    "query_list = pd.read_csv('unique_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a8daa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query only movies start year> 2000 or is null\n",
    "default_year = 2000  # Replace '\\\\N' with this default value\n",
    "query_list['startYear'] = query_list['startYear'].replace('\\\\N', 0)\n",
    "query_list['startYear'] = query_list['startYear'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a94204",
   "metadata": {},
   "source": [
    "Querying only for movie titles with start year >2020 because we only want recent information since audience preferences may change over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84a6fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = query_list.loc[query_list['startYear'] > 2020, 'primaryTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daebf08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42889"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a8db70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6549               Istoriya grazhdanskoy voyny\n",
       "52028        Histórias de Combóios em Portugal\n",
       "64136                           Loading Ludwig\n",
       "67526                    Bell of Purity Temple\n",
       "68272                       Neues in Wittstock\n",
       "                          ...                 \n",
       "222746                      A Strippers Prayer\n",
       "222749                      Mission Concepción\n",
       "222774                         Beyond the Neon\n",
       "222779    Casanova B - All you need i$ Lov(e)a\n",
       "222786                                Rankolla\n",
       "Name: primaryTitle, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "177aa0d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "20\n",
      "20\n",
      "20\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "8\n",
      "8\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "9\n",
      "9\n",
      "1\n",
      "1\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "6\n",
      "6\n",
      "12\n",
      "12\n",
      "12\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "9\n",
      "9\n",
      "0\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "111\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "8\n",
      "8\n",
      "16\n",
      "16\n",
      "16\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "0\n",
      "17\n",
      "17\n",
      "17\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "13\n",
      "13\n",
      "13\n",
      "0\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "14\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "93\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "12\n",
      "12\n",
      "12\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "10\n",
      "10\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "11\n",
      "11\n",
      "11\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "6\n",
      "6\n",
      "0\n",
      "11\n",
      "11\n",
      "11\n",
      "15\n",
      "15\n",
      "15\n",
      "3\n",
      "3\n",
      "20\n",
      "20\n",
      "20\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "7\n",
      "7\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "14\n",
      "14\n",
      "14\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12420\\964232944.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# delay by 5 seconds if no retry duration is specified by the server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query_list = query_list\n",
    "\n",
    "all_articles = []\n",
    "\n",
    "for movie_title in query_list: \n",
    "    \n",
    "    page_number = 0\n",
    "\n",
    "    while True: \n",
    "    \n",
    "       # encoded_title = quote(movie_title)\n",
    "        \n",
    "        query_params = {\n",
    "            \"api-key\": api_key,\n",
    "            \"q\": movie_title,\n",
    "            \"fq\": \"news_desk:Movies\",\n",
    "            \"begin_date\": 18510101, #start date of articles set to 1851 because articles before 1851 are arhchived, however, since movie titles are focused on >2020, the returned dates shouldn't be too long before 2020 (since there probably wouldn't be articles for the movie until planned production)\n",
    "            \"sort\": \"newest\",\n",
    "            \"page\": page_number,  # Pagination, page 0 will return the first page of results\n",
    "            \"news_desk\": \"arts\"\n",
    "            #can set \"fq\": field(\"what to serach\") to restrict fields to have specific values in the query \n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=query_params)\n",
    "\n",
    "        # Process the data as per your requirements\n",
    "        if response.status_code == 200: #request code 200 means the call was successful\n",
    "            data = response.json()\n",
    "            total_hits = data['response']['meta']['hits']\n",
    "            print(total_hits)\n",
    "\n",
    "            articles = data['response']['docs']\n",
    "\n",
    "            #check if there's any articles left to loop through\n",
    "            if not articles: #if article returned is NOT empty aka if there's no articles (if empty or is zero, returns false)\n",
    "                break #stop the loop \n",
    "\n",
    "            #loop to load article in json \n",
    "            for article in articles:\n",
    "                # Initialize author to an empty string\n",
    "                author = \"\"\n",
    "                \n",
    "                # Extract relevant fields from the article\n",
    "                headline = article.get('headline', {}).get('main', '')\n",
    "                abstract = article.get('abstract', '')\n",
    "                lead_paragraph = article.get('lead_paragraph', '')\n",
    "                snippet = article.get('snippet', '')\n",
    "                pub_date = article.get('pub_date', '')\n",
    "                news_desk = article.get('news_desk', '')\n",
    "                web_url = article.get('web_url', '')\n",
    "                source = article.get('source', '')\n",
    "                \n",
    "                persons = article.get('byline', {}).get('person', [])\n",
    "                for person in persons:\n",
    "                    first_name = person.get('firstname', '')\n",
    "                    last_name = person.get('lastname', '')\n",
    "                    if first_name and last_name:\n",
    "                        author = f\"{first_name} {last_name}\"\n",
    "                        break\n",
    "                    elif first_name:\n",
    "                        author = first_name\n",
    "                        break\n",
    "                    elif last_name:\n",
    "                        author = last_name\n",
    "                        break\n",
    "\n",
    "                if not author:\n",
    "                    author = \"N/A\"\n",
    "\n",
    "                article_info = {\n",
    "                    \"Headline\": headline,\n",
    "                    \"Abstract\": abstract,\n",
    "                    \"Lead_Paragraph\": lead_paragraph,\n",
    "                    \"Snippet\": snippet,\n",
    "                    \"Published_date\": pub_date,\n",
    "                    \"Author\": author,\n",
    "                    \"News_desk\": news_desk,\n",
    "                    \"URL\": web_url,\n",
    "                    \"Source\": source\n",
    "                }\n",
    "\n",
    "                all_articles.append(article_info)\n",
    "           \n",
    "            page_number += 1\n",
    "\n",
    "            #delay in abstracting bc there's a limit on how many articles you can retrieve based on time\n",
    "            time.sleep(1)  \n",
    "\n",
    "        elif response.status_code == 429:\n",
    "            # Rate limit exceeded, retry after suggested duration (if provided) or with an increased delay\n",
    "            retry_after = response.headers.get('Retry-After')\n",
    "            if retry_after:\n",
    "                time.sleep(int(retry_after))\n",
    "            else:\n",
    "                time.sleep(5)  # delay by 5 seconds if no retry duration is specified by the server \n",
    "\n",
    "        else:\n",
    "            print(\"Error:\", response.status_code)\n",
    "            break\n",
    "\n",
    "#save articles in a json file \n",
    "with open(\"nyt_articles.json\", \"w\") as json_file:\n",
    "    json.dump(all_articles, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba471745",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nyt_articles2.json\", \"w\") as json_file:\n",
    "    json.dump(all_articles, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34e752",
   "metadata": {},
   "source": [
    "To view the data in the first page (10 headlines) based on one title and not load in json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4840fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type in what to query in articles\n",
    "text = \"mission_impossible\"\n",
    "query = quote(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f99d89f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9759\n",
      "-----\n",
      "Headline: On Iran, Reagan's Options Don't Seem So Good, Either; No Support for New Sanctions An Array of Unsatisfying Choices\n",
      "URL: https://www.nytimes.com/1980/12/28/archives/on-iran-reagans-options-dont-seem-so-good-either-no-support-for-new.html\n",
      "-----\n",
      "Headline: Saturday; Cable/Subscription TV Of Special Interest\n",
      "URL: https://www.nytimes.com/1980/12/28/archives/saturday-cablesubscription-tv-of-special-interest.html\n",
      "-----\n",
      "Headline: Television\n",
      "URL: https://www.nytimes.com/1980/12/27/archives/television.html\n",
      "-----\n",
      "Headline: Churches Sound Ancient Message of Bethlehem; 'A Greater Awareness' 'Hear the Cries of the Poor' Churches Affirm Message of Peace on Earth and Good Will to All 'We Need Christmas' 'God Comes From Within' 'Think at Once of Family' 'You Will Respond' 'Go On With Your Life' 'Hints of Eternity' 'Time of Celebration' 'Love Is Visionary' \n",
      "URL: https://www.nytimes.com/1980/12/25/archives/churches-sound-ancient-message-of-bethlehem-a-greater-awareness.html\n",
      "-----\n",
      "Headline: U.S. TELLS OF WORRY OVER HOW HOSTAGES ARE BEING TREATED; SOME OF 52 MAY BE IN PRISONS State Department Moves to Rebut Iran's Assertion that Captives Are in Luxury Conditions Iranian Reports Are Contradicted U.S. Expresses Concern Over Hostages' Treatment Some Families Oppose Demand \n",
      "URL: https://www.nytimes.com/1980/12/23/archives/us-tells-of-worry-over-how-hostages-are-being-treated-some-of-52.html\n",
      "-----\n",
      "Headline: At Home\n",
      "URL: https://www.nytimes.com/1980/12/21/archives/connecticut-weekly-at-home.html\n",
      "-----\n",
      "Headline: At Home\n",
      "URL: https://www.nytimes.com/1980/12/21/archives/new-jersey-opinion-at-home.html\n",
      "-----\n",
      "Headline: At Home\n",
      "URL: https://www.nytimes.com/1980/12/21/archives/westchester-opinion-at-home.html\n",
      "-----\n",
      "Headline: Sunday Television; Of Special Interest SUNDAY/continued Cable/Subscription TV \n",
      "URL: https://www.nytimes.com/1980/12/21/archives/sunday-television-of-special-interest-sundaycontinued.html\n",
      "-----\n",
      "Headline: Television\n",
      "URL: https://www.nytimes.com/1980/12/14/archives/television.html\n"
     ]
    }
   ],
   "source": [
    "query_params = {\n",
    "    \"api-key\": api_key,\n",
    "    \"q\": query,\n",
    "    \"sort\": \"newest\",\n",
    "    \"page\": 0,  # Pagination, page 0 will return the first page of results\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=query_params)\n",
    "\n",
    "# Process the data as per your requirements\n",
    "if response.status_code == 200: #request code 200 means the call was successful\n",
    "    data = response.json()\n",
    "    \n",
    "    total_hits = data['response']['meta']['hits']\n",
    "    print(total_hits)\n",
    "    \n",
    "    articles = data['response']['docs']\n",
    "    for article in articles:\n",
    "        \n",
    "        print(\"-----\")\n",
    "        headline = article.get('headline', {}).get('main', '')\n",
    "        snippet = article.get('snippet', '')\n",
    "        web_url = article.get('web_url', '')\n",
    "\n",
    "        if headline:\n",
    "            print(\"Headline:\", headline)\n",
    "\n",
    "        if snippet:\n",
    "            print(\"Snippet:\", snippet)\n",
    "\n",
    "        if web_url:\n",
    "            print(\"URL:\", web_url)\n",
    "\n",
    "        #print(article['abstract'])\n",
    "        #print(\"Author:\", article['byline']['person'][0]['firstname'] + \" \" + article['byline']['person'][0]['lastname'])\n",
    "        \n",
    "        #print(article)\n",
    "            #print(\"Title:\", article[i]['display_title'])\n",
    "    #print(data)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['response']['docs'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
